{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.realpath(\"__file__\"))  # Path to notebooks directory\n",
    "parent_dir = os.path.dirname(notebook_dir)  # Parent directory of notebooks\n",
    "\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from rc.risk_control import rc_main\n",
    "from img_cls.utils import img_cls_main\n",
    "\n",
    "from plotting_style import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data'\n",
    "DATASET = \"imagenet\"\n",
    "MODELS = ['msdnet', 'dvit', 'l2wden',  'dynperc']\n",
    "\n",
    "LAMBDAS = np.arange(0., 1.001, 0.01)[::-1]  # Descending order\n",
    "DELTA = 0.1\n",
    "EPSILONS = np.arange(0.01, 0.51, 0.01)\n",
    "N_CAL = 100\n",
    "N_TRIALS = 10\n",
    "RCP_TYPES = ['ucb-wsr', 'crc']\n",
    "RISK_TYPES = ['prediction-gt-gap', 'confidence-brier', 'prediction-consistency', 'confidence-brier-top-pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: msdnet, n_cal: 100, risk_type: prediction-gt-gap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metod/miniconda3/envs/laplace/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/metod/Desktop/PhD/year2/LTT/RC-EENN/rc/bounds.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.max(np.cumsum(np.log(1 - nu * (x - mu)))) + np.log(delta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: msdnet, n_cal: 100, risk_type: confidence-brier\n",
      "Model: msdnet, n_cal: 100, risk_type: prediction-consistency\n",
      "Model: msdnet, n_cal: 100, risk_type: confidence-brier-top-pred\n",
      "Model: dvit, n_cal: 100, risk_type: prediction-gt-gap\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row, risk_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(RISK_TYPES):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_cal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_CAL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, risk_type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrisk_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     losses, exits \u001b[38;5;241m=\u001b[39m \u001b[43mimg_cls_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLAMBDAS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrisk_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrisk_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     test_risk, eff_gains, _ \u001b[38;5;241m=\u001b[39m rc_main(losses, exits, eps_grid\u001b[38;5;241m=\u001b[39mEPSILONS, rcp_types\u001b[38;5;241m=\u001b[39mRCP_TYPES, \n\u001b[1;32m      7\u001b[0m                                       delta\u001b[38;5;241m=\u001b[39mDELTA, n_cal\u001b[38;5;241m=\u001b[39mN_CAL, n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS, loss_bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrier\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m risk_type \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m     PLOT_RES[(model, risk_type)] \u001b[38;5;241m=\u001b[39m (test_risk, eff_gains)        \n",
      "File \u001b[0;32m~/Desktop/PhD/year2/LTT/RC-EENN/img_cls/utils.py:32\u001b[0m, in \u001b[0;36mimg_cls_main\u001b[0;34m(model, dataset, path, lambdas, risk_type, non_negative)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimg_cls_main\u001b[39m(\n\u001b[1;32m     24\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     25\u001b[0m     dataset: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     non_negative: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39marray]:\n\u001b[0;32m---> 32\u001b[0m     logits, targets \u001b[38;5;241m=\u001b[39m \u001b[43mread_img_cls_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     preds \u001b[38;5;241m=\u001b[39m get_preds_per_exit(logits)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# acc = get_acc_per_exit(preds, targets)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# print(logits.shape, targets.shape)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# print(acc)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PhD/year2/LTT/RC-EENN/img_cls/utils.py:17\u001b[0m, in \u001b[0;36mread_img_cls_data\u001b[0;34m(path, model, dataset)\u001b[0m\n\u001b[1;32m     14\u001b[0m     logits, targets, _ \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     16\u001b[0m logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(logits)\n\u001b[0;32m---> 17\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(logits, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits, targets\n",
      "File \u001b[0;32m~/miniconda3/envs/laplace/lib/python3.8/site-packages/torch/_tensor.py:956\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "PLOT_RES = {}\n",
    "for model in MODELS:\n",
    "    for row, risk_type in enumerate(RISK_TYPES):\n",
    "        print(f\"Model: {model}, n_cal: {N_CAL}, risk_type: {risk_type}\")\n",
    "        losses, exits = img_cls_main(model=model, dataset=DATASET, path=PATH, lambdas=LAMBDAS, risk_type=risk_type)\n",
    "        test_risk, eff_gains, _ = rc_main(losses, exits, eps_grid=EPSILONS, rcp_types=RCP_TYPES, \n",
    "                                          delta=DELTA, n_cal=N_CAL, n_trials=N_TRIALS, loss_bound=2 if 'brier' in risk_type else 1)\n",
    "        PLOT_RES[(model, risk_type)] = (test_risk, eff_gains)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = {'msdnet': 'MSDNet', 'dvit': 'DViT', 'l2wden': 'L2W-DEN', 'dynperc': 'Dyn-Perc', 'calib-msdnet/la-mie': 'Cal-MSDNet'}\n",
    "color_map = {'msdnet': 'tab:blue', 'dvit': 'tab:orange', 'l2wden': 'tab:green', 'dynperc': 'tab:red', 'calib-msdnet/la-mie': 'tab:purple'}\n",
    "risk_map = {'prediction-gt-gap': '$\\mathcal{R}^G (\\hat{y}) (0\\!-\\!1)$', 'confidence-brier': '$\\mathcal{R}^G (\\hat{p})$ (Brier)', \n",
    "            'prediction-consistency': '$\\mathcal{R}^C (\\hat{y}) (0\\!-\\!1)$', 'confidence-hellinger': '$\\mathcal{R}^C(\\hat{p})$ (Hellinger)', \n",
    "            'confidence-brier-top-pred': '$\\mathcal{R}^C (\\hat{p})$ (Brier)'}\n",
    "ls_map = {\"crc\": \"-\", \"ucb-wsr\": \"--\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def max_exit(model: str, dataset: str, path: str,) -> int:\n",
    "    with open(f\"{path}/{model}/{dataset}.p\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    if len(data) == 2:\n",
    "        logits, _ = data\n",
    "    else:\n",
    "        logits, _, _ = data\n",
    "\n",
    "    return logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_UPPER = 0.4\n",
    "_epsilons = np.append(0., EPSILONS)\n",
    "fig, ax = plt.subplots(2, len(RISK_TYPES), figsize=(text_width, 0.4*text_width), sharex=True)\n",
    "\n",
    "for j, risk_type in enumerate(RISK_TYPES):\n",
    "    max_L = 0\n",
    "    for model in MODELS[DATASET]:\n",
    "        L = max_exit(model, DATASET, PATH)\n",
    "        for rcp_type in RCP_TYPES:\n",
    "            test_risk, eff_gains = PLOT_RES[(model, risk_type)]\n",
    "            test_risk, eff_gains = np.array(test_risk[rcp_type]), np.array(eff_gains[rcp_type])\n",
    "\n",
    "            test_risk_mu = np.insert(test_risk.mean(axis=0), 0, 0)\n",
    "            eff_gains_mu = np.insert(eff_gains.mean(axis=0), 0, L)\n",
    "\n",
    "            ax[0, j].plot(_epsilons, test_risk_mu, label=model_map[model], color=color_map[model], linestyle=ls_map[rcp_type])\n",
    "            ax[1, j].plot(_epsilons, eff_gains_mu, label=model_map[model], color=color_map[model], linestyle=ls_map[rcp_type])\n",
    "\n",
    "            max_L = max(max_L, L)\n",
    "            \n",
    "            # plot a dot for (0, L) for each model\n",
    "            ax[1, j].scatter(0, L, marker='x')\n",
    "\n",
    "    if j > 0:\n",
    "        ax[0, j].set_yticklabels([])\n",
    "        ax[1, j].set_yticklabels([])\n",
    "\n",
    "    ax[0, j].set_xlim(-0.01, EPS_UPPER)\n",
    "    ax[0, j].set_ylim(0, EPS_UPPER)\n",
    "    # add a diagonal line\n",
    "    ax[0, j].plot([0, 1], [0, 1], 'k--')\n",
    "    ax[1, j].set_yticks([i for i in range(1, int(max_L) + 1)])\n",
    "\n",
    "    ax[0, j].set_title(risk_map[risk_type])\n",
    "\n",
    "ax[0, 0].set_ylabel(\"Test Risk $\\hat{\\mathcal{R}}$\")\n",
    "\n",
    "# ax[1, 1].set_xlabel(r\"Risk Level $\\epsilon$\")\n",
    "ax[1, 0].set_ylabel(\"Exit Layer ($\\downarrow$)\")\n",
    "ax[0, 0].set_xticks([i for i in np.arange(0, EPS_UPPER + 0.1, 0.1)])\n",
    "\n",
    "ax[1, 0].legend(loc='upper right')\n",
    "\n",
    "\n",
    "# add legend\n",
    "lines2 = [\n",
    "    Line2D([0], [0], color='black', lw=1, linestyle='-', alpha=0.5),\n",
    "    Line2D([0], [0], color='black', lw=1, linestyle='--', alpha=0.5),\n",
    "]\n",
    "labels2 = [\"CRC\", \"UCB\"]\n",
    "\n",
    "lines1 = [\n",
    "    Line2D([0], [0], color='tab:blue', lw=1, linestyle='-',),\n",
    "    Line2D([0], [0], color='tab:orange', lw=1, linestyle='-',),\n",
    "    Line2D([0], [0], color='tab:green', lw=1, linestyle='-',),\n",
    "    Line2D([0], [0], color='tab:red', lw=1, linestyle='-', ),\n",
    "\n",
    "]\n",
    "labels1 = [\n",
    "    \"MSDNet\",\n",
    "    \"DViT\",\n",
    "    \"L2W-DEN\",\n",
    "    \"Dyn-Perc\"\n",
    "]\n",
    "\n",
    "legend1 = ax[1, 0].legend(lines1, labels1, loc='upper right',)\n",
    "legend2 = ax[1, 1].legend(lines2, labels2, loc='upper right',)\n",
    "\n",
    "# add xlabel r\"Risk Level $\\epsilon$\" to the middle of the x-axis\n",
    "fig.text(0.52, 0.0, r\"Risk Level $\\epsilon$\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
